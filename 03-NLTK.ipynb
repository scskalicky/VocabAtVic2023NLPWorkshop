{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scskalicky/VocabAtVic2023NLPWorkshop/blob/main/03-types-tokens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcNVXxLWYcDl"
      },
      "source": [
        "## **What is a word?**\n",
        "\n",
        "- or, more precisely, how can we get Python to turn a `string` into a set of words?\n",
        "- the `str.split()` function is one way\n",
        "- this function will \"split\" a string on a pre-defined character. The default is to split on whitespace:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r9f9TcuSCtFS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['these', 'pretzels', 'are', 'making', 'me', 'thirsty']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define a string and save it to a variable\n",
        "pretzels = 'these pretzels are making me thirsty'\n",
        "\n",
        "# use .split() to convert the string into a list of segments split on whitespace\n",
        "pretzels.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The resulting object was a `list` of values, which happen to be individual words!\n",
        "\n",
        "Do you remember `len()`? How can we use `len()` and `str.split()` to count the number of words in a string?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# how to use len() and .split() to count the total number of words?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## types and tokens\n",
        "\n",
        "- types: unique words\n",
        "- tokens: occurences of unique words\n",
        "- type-token ratio (TTR): measure of lexical repetition in text\n",
        "\n",
        "#### use `set()` to find unique instances of items in a sequence\n",
        "- `set(tokens)` = all unique values\n",
        "\n",
        "#### use `len()` and `set()` to calculate TTR\n",
        "\n",
        "- `len(set(tokens))` / `len(tokens)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load in a text\n",
        "turtles = \"\"\"teenage mutant ninja turtles, \n",
        "            teenage mutant ninja turtles, \n",
        "            teenage mutant ninja turtles, \n",
        "            heroes in a halfshell, turtle power!\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert to tokens using `.split()`\n",
        "turtle_tokens = turtles.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['teenage',\n",
              " 'mutant',\n",
              " 'ninja',\n",
              " 'turtles,',\n",
              " 'teenage',\n",
              " 'mutant',\n",
              " 'ninja',\n",
              " 'turtles,',\n",
              " 'teenage',\n",
              " 'mutant',\n",
              " 'ninja',\n",
              " 'turtles,',\n",
              " 'heroes',\n",
              " 'in',\n",
              " 'a',\n",
              " 'halfshell,',\n",
              " 'turtle',\n",
              " 'power!']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# look at the tokens\n",
        "turtle_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use `len()` to count the number of words\n",
        "len(turtle_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'halfshell,',\n",
              " 'heroes',\n",
              " 'in',\n",
              " 'mutant',\n",
              " 'ninja',\n",
              " 'power!',\n",
              " 'teenage',\n",
              " 'turtle',\n",
              " 'turtles,'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use `set()` to get just the unique words\n",
        "turtle_types = set(turtle_tokens)\n",
        "turtle_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use len() and set() to count the number of types..\n",
        "len(turtle_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5555555555555556"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finally...calculate the TTR!\n",
        "\n",
        "len(turtle_types) / len(turtle_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problems with `.split()`\n",
        "\n",
        "- punctuation is retained\n",
        "- not all languages use whitespace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'yadda!', 'yadda,'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yadda = 'yadda, yadda, yadda!'\n",
        "\n",
        "set(yadda.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['对不起我的中文不好']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# not all languages use whitespace\n",
        "zhongwen = '对不起我的中文不好'\n",
        "\n",
        "zhongwen.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enter NLTK\n",
        "\n",
        "- NLTK = [Natural Language ToolKit](https://www.nltk.org/book/)\n",
        "- we will use tokenizer function from NLTK\n",
        "- we need to:\n",
        "    - import the nltk library\n",
        "    - download some resources\n",
        "\n",
        "- then we will use `nltk.word_tokenize()` to obtain tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/sskalicky/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import the library and download required resources\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare `str.split()` and `nltk.word_tokenize()` on the same text\n",
        "\n",
        "- NLTK function treats punctuation as a token\n",
        "- does this create any new challenges for text metrics?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['yadda,', 'yadda,', 'yadda!']\n"
          ]
        }
      ],
      "source": [
        "# .split() keeps punctuation attached to the word\n",
        "split_yadda = yadda.split()\n",
        "\n",
        "print(split_yadda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['yadda', ',', 'yadda', ',', 'yadda', '!']\n"
          ]
        }
      ],
      "source": [
        "# nltk tokenizer recognises punctuation\n",
        "nltk_yadda = nltk.word_tokenize(yadda)\n",
        "\n",
        "print(nltk_yadda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['You', 'know', 'we', \"'re\", 'living', 'in', 'a', 'society', '!']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# implications for contractions\n",
        "\n",
        "nltk.word_tokenize('You know we\\'re living in a society!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### conditional removal of punctuation\n",
        "- we have a better representation of words\n",
        "- but we also have punctuation as words!\n",
        "- we can use conditional expressions and tests to remove things...conditionally  \n",
        "    - remove anything that is punctuation...\n",
        "    - only keep things that are words...\n",
        "    - only keep words of certain lengths...\n",
        "- we use `if` conditional statements to do this:\n",
        "\n",
        ">```\n",
        ">\n",
        ">if condition is True:\n",
        ">    do something\n",
        ">\n",
        ">```\n",
        "\n",
        "\n",
        "#### Conditional tests include:\n",
        "\n",
        "test|syntax\n",
        "--|--\n",
        "is `a` the same as `b`?| `a == b`\n",
        "is `a` greater than `b`?|`a > b`\n",
        "is `a` less than `b`?|`a < b`\n",
        "is `a` in `b?`|`a in b`\n",
        "is `a` not in `b?`|`a not in b`\n",
        "string-specific tests|string-specific syntax\n",
        "is `a` an alphanumeric character?|`a.isalpha()`\n",
        "is `a` uppercased?|`a.isupper()`\n",
        "is `a` lowercased?|`a.islower()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NZ"
          ]
        }
      ],
      "source": [
        "# sequence through the string\n",
        "for letter in 'New Zealand':\n",
        "    # apply a test to each item in the string\n",
        "    if letter.isupper():\n",
        "        # perform an action is the test is True\n",
        "        print(letter, end = '')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN0SD9Nf71c1FiJtD0Xlkbu",
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
